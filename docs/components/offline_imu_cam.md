# Offline IMU and Camera

For the ILLIXR runtime we use the [EuRoC MAV dataset](https://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets). This dataset has stereo images and IMU (Inertial Measurement Unit) data from a drone and they have also included a ground truth pose to test the accuracy of a SLAM (Simultaneus Localization and Mapping) system.
When using this dataset without the ILLIXR runtime, OpenVINS just sequentially reads each data and uses the time stamps from the file. This allows you to get realistic SLAM results without having to actually send the data at a real sensor rate. With ILLIXR we wanted a way to be able to use these offline datasets but send the data as if it came from a realistic sensor. In ILLIXR we have a component called `offline_imu_cam` that reads camera and IMU data from the EuRoC dataset files publishes them out on a topic using Switchboard. In order to mimic a realistic sensor, the `offline_imu_cam` component measures the delta between the current sensor readings timestamp in the file and the previous reading. Then the `offline_imu_cam` component waits for that delta before publishing the sensor value out on to Switchboard. The effect results in a much more realistic system where the dataset is providing input as if a user was using a headset. 